{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import cv2\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create a utility class for camera calibration\n",
    "\n",
    "* This is used for calibrating camera and undistorting the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class cam_util():\n",
    "    \"\"\"\n",
    "        util class for camera operations\n",
    "    \"\"\"\n",
    "    ret = None\n",
    "    mtx = None\n",
    "    dist = None\n",
    "    rvecs = None\n",
    "    tvecs = None\n",
    "    \n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "    \n",
    "    def gen_camera_points(self):\n",
    "        \"\"\"\n",
    "            generate objpoints and impoints from calibration images\n",
    "        \"\"\"\n",
    "        objp = np.zeros((6*9,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "        # Make a list of calibration images\n",
    "        images = glob.glob('camera_cal/calibration*.jpg')\n",
    "        # Step through the list and search for chessboard corners\n",
    "        for fname in images:\n",
    "            img = cv2.imread(fname)\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            # Find the chessboard corners\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "            # If found, add object points, image points\n",
    "            if ret == True:\n",
    "                self.objpoints.append(objp)\n",
    "                self.imgpoints.append(corners)\n",
    "                \n",
    "    def undistort(self, img):\n",
    "        \"\"\"\n",
    "            undistort an image with camera matrix\n",
    "        \"\"\"\n",
    "        if self.mtx is None:\n",
    "            self.ret, self.mtx, self.dist, self.rvecs, self.tvecs = cv2.calibrateCamera(self.objpoints, self.imgpoints,\n",
    "                                                                                        img.shape[:2],None,None)\n",
    "        h,  w = img.shape[:2]\n",
    "        newcameramtx, roi=cv2.getOptimalNewCameraMatrix(self.mtx, self.dist, (w,h), 1, (w,h))\n",
    "        dst = cv2.undistort(img, self.mtx, self.dist, None, newcameramtx)\n",
    "        x,y,w,h = roi\n",
    "        return dst[y:y+h, x:x+w]\n",
    "    \n",
    "    def clean_mat(self):\n",
    "        \"\"\"\n",
    "            Reset camera calibration\n",
    "        \"\"\"\n",
    "        self.ret = None\n",
    "        self.mtx = None\n",
    "        self.dist = None\n",
    "        self.rvecs = None\n",
    "        self.tvecs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create a class to keep track of lane detections\n",
    "\n",
    "* Here we use the average of last maxSamples to identify the lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "    \"\"\"\n",
    "        class to store detected lane stats\n",
    "    \"\"\"\n",
    "    def __init__(self, maxSamples=15):\n",
    "        \n",
    "        self.maxSamples = maxSamples \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = deque(maxlen=self.maxSamples)\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float')\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "         \n",
    "    def update_lane(self, ally, allx):\n",
    "        \"\"\"\n",
    "            Function to update the stats\n",
    "        \"\"\"\n",
    "        # get the mean as the best x \n",
    "        self.bestx = np.mean(allx, axis=0)\n",
    "        # fit a 2 order polynomial\n",
    "        new_fit = np.polyfit(ally, allx, 2)\n",
    "        # calculate the difference between last fit and new fit\n",
    "        self.diffs = np.subtract(self.current_fit, new_fit)\n",
    "        # update current fit\n",
    "        self.current_fit = new_fit\n",
    "        # add the new fit to the queue\n",
    "        self.recent_xfitted.append(self.current_fit)\n",
    "        # Use the queue mean as the best fit\n",
    "        self.best_fit = np.mean(self.recent_xfitted, axis=0)\n",
    "        # meters per pixel in y dimension\n",
    "        ym_per_pix = 30/720\n",
    "        # meters per pixel in x dimension\n",
    "        xm_per_pix = 3.7/700\n",
    "        # Calculate radius of curvature\n",
    "        fit_cr = np.polyfit(ally*ym_per_pix, allx*xm_per_pix, 2)\n",
    "        y_eval = np.max(ally)\n",
    "        self.radius_of_curvature = ((1 + (2*fit_cr[0]*y_eval*ym_per_pix + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "\n",
    "def get_roi(img, vertices):\n",
    "    \"\"\"\n",
    "        Apply mask and get region of interest within the mask\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255 \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def hide_roi(img, vertices):\n",
    "    \"\"\"\n",
    "        Apply mask and get region of interest outside the mask\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(img)\n",
    "    mask=mask+255\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (0,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 0 \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def drow_on_images(img, vertices):\n",
    "    \"\"\"\n",
    "        Draw ploygon on image\n",
    "    \"\"\"\n",
    "    cv2.polylines(img, [vertices], True, (255,255,255), 2)\n",
    "    plot_img(img, 'img drawing', True)\n",
    "\n",
    "def plot_img(img, step, show_stages=False):\n",
    "    \"\"\"\n",
    "        plot image\n",
    "    \"\"\"\n",
    "    if show_stages:\n",
    "        print('######################## '+step+' ########################')\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "    \n",
    "def plot_hist(histogram, show_stages=False):\n",
    "    \"\"\"\n",
    "        plot histogram\n",
    "    \"\"\"\n",
    "    if show_stages:\n",
    "        print('######################## histogram ########################')\n",
    "        plt.plot(histogram)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Use the lane pixals identified to fit a ploygon and draw it back on the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_stats(img):\n",
    "    \"\"\"\n",
    "        Write lane stats on image\n",
    "    \"\"\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    size = 1\n",
    "    weight = 2\n",
    "    color = (255,70,0)\n",
    "    cv2.putText(img,'Left Curve : '+ '{0:.2f}'.format(left_line.radius_of_curvature)+' m',(10,30), font, size, color, weight)\n",
    "    cv2.putText(img,'Right Curve : '+ '{0:.2f}'.format(right_line.radius_of_curvature)+' m',(10,60), font, size, color, weight)\n",
    "    cv2.putText(img,'Left Lane Pos: '+ '{0:.2f}'.format(left_line.bestx),(10,100), font, size, color, weight)\n",
    "    cv2.putText(img,'Right Lane Pos: '+ '{0:.2f}'.format(right_line.bestx),(10,130), font, size, color, weight)\n",
    "    cv2.putText(img,'Distance from center: '+ \"{0:.2f}\".format(left_line.line_base_pos)+' m',(10,180), font, size, color, weight)\n",
    "    \n",
    "def draw_lane(undist, img, Minv):\n",
    "    \"\"\"\n",
    "        Draw the detected lane bak on the image\n",
    "    \"\"\"\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(300, 700)\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    left_fit = left_line.best_fit\n",
    "    right_fit = right_line.best_fit\n",
    "    \n",
    "    if left_fit is not None and right_fit is not None:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (20,120, 80))\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "        write_stats(result)\n",
    "        return result\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Here we validate the detected lines and add them to the lane class\n",
    "\n",
    "## A valid detection satisfies below rules\n",
    "\n",
    "* Minmum number of pixals must be greater than 2000\n",
    "* Left lane mean should be more than a minimum\n",
    "* Right lane mean should be less then a minimum\n",
    "* Lane width whoud be atlest 300 and atmost 800\n",
    "* New detections must be within 100px of the average of last n detections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def validate_Update_lane(img, nonzero, nonzerox, nonzeroy, left_lane_inds, right_lane_inds, show_stages=False):\n",
    "    \"\"\"\n",
    "        Validate the detected lane ids and update the lane stats if valid.\n",
    "    \"\"\"\n",
    "    # Extract left and right line pixel positions\n",
    "    left_line_allx = nonzerox[left_lane_inds]\n",
    "    left_line_ally = nonzeroy[left_lane_inds] \n",
    "    right_line_allx = nonzerox[right_lane_inds]\n",
    "    right_line_ally = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Discard the detections if any of the detected lane is less than 2000 pixals. \n",
    "    # This is done because for very small size the poly fit function gives unpredictable results.\n",
    "    # A better approch would be to use the largest lane curvature to extend the other one\n",
    "    if len(left_line_allx) <= 2000 or len(right_line_allx) <= 2000:\n",
    "        left_line.detected = False\n",
    "        right_line.detected = False\n",
    "        return\n",
    "    \n",
    "    left_x_mean = np.mean(left_line_allx, axis=0)\n",
    "    right_x_mean = np.mean(right_line_allx, axis=0)\n",
    "    lane_width = np.subtract(right_x_mean, left_x_mean)\n",
    "    \n",
    "    # Discard the detections if the lane with is too large or too small\n",
    "    if left_x_mean > 450 or right_x_mean < 850:\n",
    "        left_line.detected = False\n",
    "        right_line.detected = False\n",
    "        return\n",
    "    if  lane_width < 300 or lane_width > 800:\n",
    "        left_line.detected = False\n",
    "        right_line.detected = False\n",
    "        return \n",
    "    \n",
    "    # Update the lane stats if the current detection is the first one or\n",
    "    # the detection is within 100 pixals of the last n detection mean\n",
    "    if left_line.bestx is None or np.abs(np.subtract(left_line.bestx, np.mean(left_line_allx, axis=0))) < 100:\n",
    "        left_line.update_lane(left_line_ally, left_line_allx)\n",
    "        left_line.detected = True\n",
    "    else:\n",
    "        left_line.detected = False\n",
    "    if right_line.bestx is None or np.abs(np.subtract(right_line.bestx, np.mean(right_line_allx, axis=0))) < 100:\n",
    "        right_line.update_lane(right_line_ally, right_line_allx)\n",
    "        right_line.detected = True\n",
    "    else:\n",
    "        right_line.detected = False\n",
    "    \n",
    "    # Calculate the distance of car from center of lane\n",
    "    lane_center = right_line.bestx - left_line.bestx\n",
    "    left_line.line_base_pos = ((img.shape[1]*0.5 - lane_center)*3.7)/700\n",
    "    right_line.line_base_pos = left_line.line_base_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Find the lane using sliding window technique\n",
    "\n",
    "* Use the minimum of bottom 1/4 of the histogram to find the initial left and right base\n",
    "* Use the base points to find more points within a margin and min number of pixals\n",
    "* Using \n",
    "* windows size = 9 \n",
    "* margin = 80\n",
    "* min pixals = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def window_search(img, nonzero, nonzerox, nonzeroy, show_stages=False):\n",
    "    \"\"\"\n",
    "        Perform a sliding window search to detect lane pixals.\n",
    "    \"\"\"\n",
    "    # Temp image to draw detections on\n",
    "    out_img = np.dstack((img, img, img))*255\n",
    "    # Calculate histogram\n",
    "    histogram = np.sum(img[img.shape[0]*.75:,:], axis=0)\n",
    "    plot_hist(histogram, show_stages)\n",
    "    # Take the midpoint and use the max on each side as starting point\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[0:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:histogram.shape[0]]) + midpoint\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 80\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 30\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        \n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low)\n",
    "                          & (nonzeroy < win_y_high)\n",
    "                          & (nonzerox >= win_xleft_low)\n",
    "                          & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low)\n",
    "                           & (nonzeroy < win_y_high)\n",
    "                           & (nonzerox >= win_xright_low)\n",
    "                           & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds])) \n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "            \n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    plot_img(out_img, 'sliding window marked', show_stages)\n",
    "    return left_lane_inds, right_lane_inds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Find Lanes Wrapper\n",
    "\n",
    "* If left or right lane found in the last iteration. Get the pixals in a margin of 30 and validate\n",
    "\n",
    "* If the validation fails or this is the first iteration use the sliding window technique to find lanes and then validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_lanes(img, show_stages=False):\n",
    "    \"\"\"\n",
    "        Lane finding wrapper function\n",
    "    \"\"\"\n",
    "    # Get the foreground pixals\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # If the last detection was successful take the non zero pixals within the 30 pixal margin as the new detections\n",
    "    if left_line.detected and right_line.detected:\n",
    "        margin = 30\n",
    "        left_lane_inds = ((nonzerox > (left_line.current_fit[0]*(nonzeroy**2) + left_line.current_fit[1]*nonzeroy + left_line.current_fit[2] - margin))\n",
    "                          & (nonzerox < (left_line.current_fit[0]*(nonzeroy**2) + left_line.current_fit[1]*nonzeroy + left_line.current_fit[2] + margin))) \n",
    "        right_lane_inds = ((nonzerox > (right_line.current_fit[0]*(nonzeroy**2) + right_line.current_fit[1]*nonzeroy + right_line.current_fit[2] - margin))\n",
    "                           & (nonzerox < (right_line.current_fit[0]*(nonzeroy**2) + right_line.current_fit[1]*nonzeroy + right_line.current_fit[2] + margin)))\n",
    "        # Update the lane detections\n",
    "        validate_Update_lane(img, nonzero, nonzerox, nonzeroy, left_lane_inds, right_lane_inds)\n",
    "    # If first detection or the last detection was unsuccessful perform a sliding window search\n",
    "    else:\n",
    "        #print('doing window search')\n",
    "        left_lane_inds, right_lane_inds = window_search(img, nonzero, nonzerox, nonzeroy, show_stages)\n",
    "        # Update the lane detections\n",
    "        validate_Update_lane(img, nonzero, nonzerox, nonzeroy, left_lane_inds, right_lane_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Warp the image to get birds' eye view\n",
    "\n",
    "* Use source points\n",
    "    * bounding_top_right = [img_shape[1]*0.5 + 90,img_shape[0]*0.70]\n",
    "    * bounding_btm_right = [img_shape[1]*0.5 + 450,img_shape[0]]\n",
    "    * bounding_btm_left  = [img_shape[1]*0.5 - 400,img_shape[0]]\n",
    "    * bounding_top_left  = [img_shape[1]*0.5 - 60,img_shape[0]*0.70]\n",
    "\n",
    "* Destinations points\n",
    "    * bounding_top_right = [img_shape[1]*0.5 + 250,img_shape[0]*0.60]\n",
    "    * bounding_btm_right = [img_shape[1]*0.5 + 390,img_shape[0]]\n",
    "    * bounding_btm_left  = [img_shape[1]*0.5 - 345,img_shape[0]]\n",
    "    * bounding_top_left  = [img_shape[1]*0.5 - 205,img_shape[0]*0.60]\n",
    "    \n",
    "* Get perpective transform\n",
    "* Get inverse perpective transform\n",
    "* warp the image using perspective transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def warp(img):\n",
    "    \"\"\"\n",
    "        Warp the image to get birds eye view.\n",
    "    \"\"\"\n",
    "    img_shape = img.shape\n",
    "    bounding_top_right = [img_shape[1]*0.5 + 90,img_shape[0]*0.70]\n",
    "    bounding_btm_right = [img_shape[1]*0.5 + 450,img_shape[0]]\n",
    "    bounding_btm_left  = [img_shape[1]*0.5 - 400,img_shape[0]]\n",
    "    bounding_top_left  = [img_shape[1]*0.5 - 60,img_shape[0]*0.70]\n",
    "    # Select source points\n",
    "    pts1 = np.float32([bounding_top_right,bounding_btm_right,bounding_btm_left,bounding_top_left])\n",
    "    # Select destination points\n",
    "    pts2 = np.float32([[img_shape[1]*0.5 + 250,img_shape[0]*0.60],\n",
    "                   [img_shape[1]*0.5 + 390,img_shape[0]],\n",
    "                   [img_shape[1]*0.5 - 345,img_shape[0]],\n",
    "                   [img_shape[1]*0.5 - 205,img_shape[0]*0.60]])\n",
    "    # Get Perspective Transform \n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    # Get inverse Perspective Transform \n",
    "    Minv = cv2.getPerspectiveTransform(pts2, pts1)\n",
    "    # Apply warp transform on source image\n",
    "    dst = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return dst, Minv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Threshold\n",
    "\n",
    "* Use color threshold\n",
    "    * The number of lane pixals must be considerably less than the background pixals and have a minimum value.\n",
    "    * We use this to recursively increase or decrease the minimum threshold value to find the optimal value.\n",
    "* Use Sobel operator to find gradients\n",
    "* Combine the two to get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rec_threshold(img, roi, t_min=140, t_max=255):\n",
    "    \"\"\"\n",
    "        Funtion to apply recursive threshold with increasing/decreasing boundries\n",
    "        based on the area of lane within a region of interest.\n",
    "    \"\"\"\n",
    "    binary = np.zeros_like(img)\n",
    "    binary[(img >= t_min) & (img <= t_max)] = 1\n",
    "    # retrun last val if the threshold levels reach minimum or maximum.\n",
    "    if t_min <= 40 or t_min >= 220:\n",
    "        return binary\n",
    "    binary_1 = get_roi(binary, roi)\n",
    "    #print(np.sum(binary_1.nonzero()))\n",
    "    if np.sum(binary_1.nonzero()) > 9800000:\n",
    "        binary = rec_threshold(img, roi, t_min+10)\n",
    "    elif np.sum(binary_1.nonzero()) < 100000:\n",
    "        binary = rec_threshold(img, roi, t_min-10)    \n",
    "    return binary\n",
    "\n",
    "def threshold(img, roi, show_stages=False):\n",
    "    \"\"\"\n",
    "        Apply threshold\n",
    "    \"\"\"\n",
    "    # Convert image the HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    # Take v channel\n",
    "    v_channel = hsv[:,:,2]\n",
    "    plot_img(v_channel, 'v channel', show_stages)\n",
    "    # Apply threshold to find lane\n",
    "    v_binary = rec_threshold(v_channel, roi)\n",
    "    plot_img(v_binary, 'color threshold', show_stages)\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take the derivative in x\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_32F, 1, 0)\n",
    "    #sobelx = cv2.Sobel(sobelx, cv2.CV_32F, 0, 1) # Take the derivative \n",
    "    #plot_img(sobelx, show_stages)\n",
    "    # Absolute x derivative to \n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    #accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    #plot_img(sobelx, show_stages)\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    # perform threshold\n",
    "    sxbinary[(scaled_sobel >= 100) & (scaled_sobel <= 255)] = 1\n",
    "    plot_img(sobelx, 'sobel', show_stages)\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, v_binary))\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    # conbine color and sobel threshold\n",
    "    combined_binary[(v_binary == 1) | (sxbinary == 1)] = 1\n",
    "    plot_img(combined_binary, 'combined threshold', show_stages)\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Apply all the steps\n",
    "\n",
    "* Undistort the image\n",
    "* Apply perspective transform\n",
    "* Apply threshold\n",
    "* Find lanes\n",
    "* Draw the result back on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_image(image, show_stages=False):\n",
    "    \"\"\"\n",
    "        Wrapper function for all image processing\n",
    "    \"\"\"\n",
    "    # Undistort the image\n",
    "    undistorted = cam.undistort(image)\n",
    "    plot_img(undistorted, 'undistorted', show_stages)\n",
    "    # Apply perpective transform\n",
    "    img, Minv = warp(undistorted)\n",
    "    plot_img(img, 'warped', show_stages)\n",
    "    # Get points for region of interst\n",
    "    vertices = np.array([[(image.shape[1]*0.1,image.shape[0]-50),\n",
    "                        (image.shape[1]*0.5-100,image.shape[0]*0.60),\n",
    "                        (image.shape[1]*0.5+100,image.shape[0]*0.60),\n",
    "                        (image.shape[1]*0.95,image.shape[0]-50)]], \n",
    "                        dtype=np.int32)\n",
    "    # Apply threshold\n",
    "    img = threshold(img, vertices, show_stages)\n",
    "    vertices = np.array([[(200,img.shape[0]),\n",
    "                          (200,0),\n",
    "                          (1050,0),\n",
    "                          (1050,img.shape[0])]], dtype=np.int32)\n",
    "    # Get roi\n",
    "    img = get_roi(img, vertices)\n",
    "    # Find Lanes\n",
    "    find_lanes(img, show_stages)\n",
    "    # Draw lanes on image\n",
    "    res = draw_lane(undistorted, img, Minv);    \n",
    "    #plot_img(res, show_stages)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generate obj points and img points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# init camera\n",
    "cam = cam_util()\n",
    "cam.gen_camera_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Calibrate camera and undistort the chessbaord images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Undistort a sample calibration image\n",
    "cal_dir = \"camera_cal/\"\n",
    "cal_images = glob.glob(cal_dir+'*.jpg')\n",
    "\n",
    "for cal_image in cal_images:\n",
    "    cimg = mpimg.imread(cal_image)\n",
    "    cimg_undistort = cam.undistort(cimg)\n",
    "    cv2.imwrite('output_images/undistort_'+cal_image.split('/')[1],cimg_undistort)\n",
    "print('calibration done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean camera matrix\n",
    "cam.clean_mat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test on images\n",
    "test_dir = \"test_images/\"\n",
    "test_images = glob.glob(test_dir+'test*.jpg')\n",
    "#test_images = glob.glob(test_dir+'straight_lines*.jpg')\n",
    "#test_images = glob.glob(test_dir+'*.jpg')\n",
    "for test_image in test_images:\n",
    "    left_line = Line()\n",
    "    right_line = Line()\n",
    "    image = mpimg.imread(test_image)\n",
    "    res = process_image(image, False)\n",
    "    #plot_img(res, True)\n",
    "\n",
    "print('######################## Sample Stages ########################')\n",
    "print()\n",
    "# display stages for a sample image\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "image = mpimg.imread('test_images/test3.jpg')\n",
    "plot_img(image, 'Initial', True)\n",
    "res = process_image(image, True)\n",
    "plot_img(res, 'Final', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test on Videos\n",
    "\n",
    "# Clean data for video\n",
    "#\"\"\"\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "cam.clean_mat()\n",
    "project_video_res = 'project_video_res.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "project_video_clip = clip1.fl_image(process_image)\n",
    "project_video_clip.write_videofile(project_video_res, audio=False)\n",
    "#\"\"\"\n",
    "\n",
    "# Clean data for video\n",
    "#\"\"\"\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "cam.clean_mat()\n",
    "challenge_video_res = 'challenge_video_res.mp4'\n",
    "clip2 = VideoFileClip('challenge_video.mp4')\n",
    "challenge_video_clip = clip2.fl_image(process_image)\n",
    "challenge_video_clip.write_videofile(challenge_video_res, audio=False)\n",
    "#\"\"\"\n",
    "\n",
    "# Clean data for video\n",
    "#\"\"\"\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "cam.clean_mat()\n",
    "harder_challenge_video_res = 'harder_challenge_video_res.mp4'\n",
    "clip2 = VideoFileClip('harder_challenge_video.mp4')\n",
    "harder_challenge_video_clip = clip2.fl_image(process_image)\n",
    "harder_challenge_video_clip.write_videofile(harder_challenge_video_res, audio=False)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
